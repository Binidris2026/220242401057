{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a2ec1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from surprise import Reader, Dataset, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35507e4",
   "metadata": {},
   "source": [
    "QUESTION 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b5a4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "Faceplate_df = pd.read_csv(r\"C:\\Users\\ALLY ALLY\\Downloads\\Faceplate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d1f5498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 transactions:\n",
      "   Transaction  Red  White  Blue  Orange  Green  Yellow\n",
      "0            1    1      1     0       0      1       0\n",
      "1            2    0      1     0       1      0       0\n",
      "2            3    0      1     1       0      0       0\n",
      "3            4    1      1     0       1      0       0\n",
      "4            5    1      0     1       0      0       0\n",
      "5            6    0      1     1       0      0       0\n",
      "6            7    1      0     1       0      0       0\n",
      "7            8    1      1     1       0      1       0\n",
      "8            9    1      1     1       0      0       0\n",
      "9           10    0      0     0       0      0       1\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 transactions:\")\n",
    "print(Faceplate_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24f578",
   "metadata": {},
   "source": [
    "QUESTION 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c8d07c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support count of {Red, White}: 4\n",
      "Support proportion: 0.4\n"
     ]
    }
   ],
   "source": [
    "support_count = Faceplate_df[\n",
    "    (Faceplate_df['Red'] == 1) &\n",
    "    (Faceplate_df['White'] == 1)\n",
    "].shape[0]\n",
    "\n",
    "total_transactions = len(Faceplate_df)\n",
    "support_pct = support_count / total_transactions\n",
    "\n",
    "print(\"\\nSupport count of {Red, White}:\", support_count)\n",
    "print(\"Support proportion:\", support_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e729d5e",
   "metadata": {},
   "source": [
    "QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c7ba9170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets (Faceplate):\n",
      "    support                        itemsets\n",
      "0       0.6                frozenset({Red})\n",
      "1       0.7              frozenset({White})\n",
      "2       0.6               frozenset({Blue})\n",
      "3       0.2             frozenset({Orange})\n",
      "4       0.2              frozenset({Green})\n",
      "5       0.4         frozenset({Red, White})\n",
      "6       0.4          frozenset({Red, Blue})\n",
      "7       0.2         frozenset({Red, Green})\n",
      "8       0.4        frozenset({White, Blue})\n",
      "9       0.2      frozenset({White, Orange})\n",
      "10      0.2       frozenset({White, Green})\n",
      "11      0.2   frozenset({Red, White, Blue})\n",
      "12      0.2  frozenset({Red, White, Green})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ALLY ALLY\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:175: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_encoded = Faceplate_df.drop('Transaction', axis=1)\n",
    "\n",
    "frequent_itemsets_faceplate = apriori(\n",
    "    df_encoded,\n",
    "    min_support=0.2,\n",
    "    use_colnames=True\n",
    ")\n",
    "\n",
    "print(\"\\nFrequent Itemsets (Faceplate):\")\n",
    "print(frequent_itemsets_faceplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7bc44108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 6 Rules (Faceplate):\n",
      "                  antecedents              consequents  support  confidence  \\\n",
      "12    frozenset({Red, White})       frozenset({Green})      0.2         0.5   \n",
      "15         frozenset({Green})  frozenset({Red, White})      0.2         1.0   \n",
      "4          frozenset({Green})         frozenset({Red})      0.2         1.0   \n",
      "14  frozenset({White, Green})         frozenset({Red})      0.2         1.0   \n",
      "7         frozenset({Orange})       frozenset({White})      0.2         1.0   \n",
      "8          frozenset({Green})       frozenset({White})      0.2         1.0   \n",
      "\n",
      "        lift  leverage  \n",
      "12  2.500000      0.12  \n",
      "15  2.500000      0.12  \n",
      "4   1.666667      0.08  \n",
      "14  1.666667      0.08  \n",
      "7   1.428571      0.06  \n",
      "8   1.428571      0.06  \n"
     ]
    }
   ],
   "source": [
    "rules_faceplate = association_rules(\n",
    "    frequent_itemsets_faceplate,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=0.5\n",
    ")\n",
    "\n",
    "rules_faceplate = rules_faceplate.sort_values(by='lift', ascending=False)\n",
    "\n",
    "top_6_rules_faceplate = rules_faceplate.head(6)[\n",
    "    ['antecedents', 'consequents',\n",
    "     'support', 'confidence',\n",
    "     'lift', 'leverage']\n",
    "]\n",
    "\n",
    "print(\"\\nTop 6 Rules (Faceplate):\")\n",
    "print(top_6_rules_faceplate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517a8e1e",
   "metadata": {},
   "source": [
    "QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "84f8a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_charlesbook = pd.read_csv(r\"C:\\Users\\ALLY ALLY\\Downloads\\CharlesBookClub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb776d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of Book Binary Matrix:\n",
      "   ChildBks  YouthBks  CookBks  DoItYBks  RefBks  ArtBks  GeogBks  ItalCook  \\\n",
      "0         0         1        1         0       0       0        0         0   \n",
      "1         0         0        0         0       0       0        0         0   \n",
      "2         1         1        1         0       1       0        1         1   \n",
      "3         0         0        0         0       0       0        0         0   \n",
      "4         0         0        0         0       0       0        0         0   \n",
      "5         0         0        0         0       0       0        0         0   \n",
      "6         0         0        0         0       0       0        1         0   \n",
      "7         1         0        0         0       0       0        0         0   \n",
      "8         0         0        0         0       0       0        0         0   \n",
      "9         0         0        1         0       0       0        0         0   \n",
      "\n",
      "   ItalAtlas  ItalArt  Florence  \n",
      "0          0        0         0  \n",
      "1          0        0         0  \n",
      "2          0        0         0  \n",
      "3          0        0         0  \n",
      "4          0        0         0  \n",
      "5          0        0         0  \n",
      "6          0        0         0  \n",
      "7          0        0         0  \n",
      "8          0        0         0  \n",
      "9          0        0         0  \n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['Seq#', 'ID#', 'Gender', 'M', 'R', 'F',\n",
    "                'FirstPurch', 'Related Purchase',\n",
    "                'Mcode', 'Rcode', 'Fcode',\n",
    "                'Yes_Florence', 'No_Florence']\n",
    "\n",
    "book_cols = [col for col in df_charlesbook.columns if col not in exclude_cols]\n",
    "\n",
    "binary_matrix = (df_charlesbook[book_cols] > 0).astype(int)\n",
    "\n",
    "print(\"\\nFirst 10 rows of Book Binary Matrix:\")\n",
    "print(binary_matrix.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "48a4fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of frequent itemsets (Books): 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ALLY ALLY\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:175: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "min_support_ratio_books = 200 / len(binary_matrix)\n",
    "\n",
    "frequent_itemsets_books = apriori(\n",
    "    binary_matrix,\n",
    "    min_support=min_support_ratio_books,\n",
    "    use_colnames=True\n",
    ")\n",
    "\n",
    "print(\"\\nNumber of frequent itemsets (Books):\",\n",
    "      len(frequent_itemsets_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e8a25a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 25 Rules (Books):\n",
      "                                 antecedents                     consequents  \\\n",
      "64             frozenset({YouthBks, RefBks})  frozenset({ChildBks, CookBks})   \n",
      "73             frozenset({DoItYBks, RefBks})  frozenset({ChildBks, CookBks})   \n",
      "60           frozenset({YouthBks, DoItYBks})  frozenset({ChildBks, CookBks})   \n",
      "80              frozenset({GeogBks, RefBks})  frozenset({ChildBks, CookBks})   \n",
      "69            frozenset({YouthBks, GeogBks})  frozenset({ChildBks, CookBks})   \n",
      "77            frozenset({DoItYBks, GeogBks})  frozenset({ChildBks, CookBks})   \n",
      "68   frozenset({ChildBks, CookBks, GeogBks})           frozenset({YouthBks})   \n",
      "71    frozenset({ChildBks, CookBks, RefBks})           frozenset({DoItYBks})   \n",
      "49            frozenset({DoItYBks, GeogBks})           frozenset({YouthBks})   \n",
      "63    frozenset({ChildBks, CookBks, RefBks})           frozenset({YouthBks})   \n",
      "59  frozenset({DoItYBks, ChildBks, CookBks})           frozenset({YouthBks})   \n",
      "57  frozenset({YouthBks, ChildBks, CookBks})           frozenset({DoItYBks})   \n",
      "33             frozenset({ChildBks, RefBks})           frozenset({DoItYBks})   \n",
      "75   frozenset({ChildBks, CookBks, GeogBks})           frozenset({DoItYBks})   \n",
      "21            frozenset({ChildBks, GeogBks})           frozenset({YouthBks})   \n",
      "46             frozenset({CookBks, GeogBks})           frozenset({YouthBks})   \n",
      "61   frozenset({YouthBks, ChildBks, RefBks})            frozenset({CookBks})   \n",
      "16           frozenset({YouthBks, ChildBks})           frozenset({DoItYBks})   \n",
      "51              frozenset({CookBks, RefBks})           frozenset({DoItYBks})   \n",
      "28                       frozenset({RefBks})  frozenset({ChildBks, CookBks})   \n",
      "72    frozenset({DoItYBks, CookBks, RefBks})           frozenset({ChildBks})   \n",
      "15                     frozenset({YouthBks})  frozenset({ChildBks, CookBks})   \n",
      "70   frozenset({DoItYBks, ChildBks, RefBks})            frozenset({CookBks})   \n",
      "23            frozenset({ChildBks, CookBks})           frozenset({DoItYBks})   \n",
      "25                     frozenset({DoItYBks})  frozenset({ChildBks, CookBks})   \n",
      "\n",
      "    support  confidence      lift  leverage  \n",
      "64  0.05525    0.680000  2.809917  0.035588  \n",
      "73  0.06125    0.662162  2.736207  0.038865  \n",
      "60  0.06700    0.648910  2.681448  0.042014  \n",
      "80  0.05025    0.614679  2.539995  0.030467  \n",
      "69  0.06325    0.605263  2.501087  0.037961  \n",
      "77  0.06050    0.599010  2.475248  0.036058  \n",
      "68  0.06325    0.577626  2.424452  0.037162  \n",
      "71  0.06125    0.591787  2.323013  0.034883  \n",
      "49  0.05450    0.539604  2.264864  0.030437  \n",
      "63  0.05525    0.533816  2.240573  0.030591  \n",
      "59  0.06700    0.524462  2.201309  0.036564  \n",
      "57  0.06700    0.558333  2.191691  0.036430  \n",
      "33  0.07100    0.553606  2.173135  0.038328  \n",
      "75  0.06050    0.552511  2.168838  0.032605  \n",
      "21  0.07550    0.516239  2.166797  0.040656  \n",
      "46  0.08025    0.513600  2.155719  0.043023  \n",
      "61  0.05525    0.891129  2.144715  0.029489  \n",
      "16  0.08025    0.544068  2.135693  0.042674  \n",
      "51  0.07450    0.533095  2.092619  0.038899  \n",
      "28  0.10350    0.505495  2.088820  0.053950  \n",
      "72  0.06125    0.822148  2.086669  0.031897  \n",
      "15  0.12000    0.503673  2.081292  0.062344  \n",
      "70  0.06125    0.862676  2.076236  0.031749  \n",
      "23  0.12775    0.527893  2.072198  0.066101  \n",
      "25  0.12775    0.501472  2.072198  0.066101  \n"
     ]
    }
   ],
   "source": [
    "rules_books = association_rules(\n",
    "    frequent_itemsets_books,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=0.5\n",
    ")\n",
    "\n",
    "rules_books = rules_books.sort_values(by='lift', ascending=False)\n",
    "\n",
    "top_25_rules_books = rules_books.head(25)[\n",
    "    ['antecedents', 'consequents',\n",
    "     'support', 'confidence',\n",
    "     'lift', 'leverage']\n",
    "]\n",
    "\n",
    "print(\"\\nTop 25 Rules (Books):\")\n",
    "print(top_25_rules_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c20731",
   "metadata": {},
   "source": [
    "QUESTION  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c9bea4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest Support Rule:\n",
      "antecedents     frozenset({CookBks})\n",
      "consequents    frozenset({ChildBks})\n",
      "support                        0.242\n",
      "confidence                  0.582431\n",
      "lift                        1.478251\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "highest_support_rule = rules_books.sort_values(\n",
    "    by='support', ascending=False).iloc[0]\n",
    "\n",
    "print(\"\\nHighest Support Rule:\")\n",
    "print(highest_support_rule[['antecedents', 'consequents',\n",
    "                            'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d87651a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest Lift Rule:\n",
      "antecedents     frozenset({YouthBks, RefBks})\n",
      "consequents    frozenset({ChildBks, CookBks})\n",
      "support                               0.05525\n",
      "confidence                               0.68\n",
      "lift                                 2.809917\n",
      "Name: 64, dtype: object\n"
     ]
    }
   ],
   "source": [
    "highest_lift_rule_books = rules_books.sort_values(\n",
    "    by='lift', ascending=False).iloc[0]\n",
    "\n",
    "print(\"\\nHighest Lift Rule:\")\n",
    "print(highest_lift_rule_books[['antecedents', 'consequents',\n",
    "                               'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "efc8d816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lowest Confidence Rule among Top 10 Lift:\n",
      "antecedents    frozenset({ChildBks, CookBks, RefBks})\n",
      "consequents                     frozenset({YouthBks})\n",
      "support                                       0.05525\n",
      "confidence                                   0.533816\n",
      "lift                                         2.240573\n",
      "Name: 63, dtype: object\n"
     ]
    }
   ],
   "source": [
    "top_10_lift_books = rules_books.sort_values(\n",
    "    by='lift', ascending=False).head(10)\n",
    "\n",
    "lowest_conf_rule = top_10_lift_books.sort_values(\n",
    "    by='confidence', ascending=True).iloc[0]\n",
    "\n",
    "print(\"\\nLowest Confidence Rule among Top 10 Lift:\")\n",
    "print(lowest_conf_rule[['antecedents', 'consequents',\n",
    "                        'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08795b6",
   "metadata": {},
   "source": [
    "QUESTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fddba348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Synthetic Dataset Shape: (50, 9)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "synthetic = pd.DataFrame(\n",
    "    np.random.randint(0, 2, size=(50, 9)),\n",
    "    columns=[1,2,3,4,5,6,7,8,9]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "synthetic_data = pd.DataFrame(\n",
    "    np.random.choice([0, 1], size=(50, 9), p=[0.7, 0.3]),\n",
    "    columns=[f'Item_{i+1}' for i in range(9)]\n",
    ")\n",
    "\n",
    "\n",
    "df_synthetic = synthetic_data\n",
    "synthetic_dataset = synthetic_data\n",
    "\n",
    "print(\"\\nSynthetic Dataset Shape:\", synthetic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "68f4c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ALLY ALLY\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:175: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets_synthetic = apriori(\n",
    "    synthetic_data,\n",
    "    min_support=2/50,\n",
    "    use_colnames=True\n",
    ")\n",
    "\n",
    "rules_synthetic = association_rules(\n",
    "    frequent_itemsets_synthetic,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "08aa1703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 6 Synthetic Rules (by Lift):\n",
      "                            antecedents                          consequents  \\\n",
      "64          frozenset({Item_7, Item_4})  frozenset({Item_8, Item_1, Item_6})   \n",
      "53  frozenset({Item_2, Item_7, Item_8})          frozenset({Item_1, Item_6})   \n",
      "60  frozenset({Item_8, Item_7, Item_4})          frozenset({Item_1, Item_6})   \n",
      "32          frozenset({Item_7, Item_4})          frozenset({Item_1, Item_6})   \n",
      "48          frozenset({Item_7, Item_4})          frozenset({Item_8, Item_6})   \n",
      "61  frozenset({Item_8, Item_4, Item_6})          frozenset({Item_7, Item_1})   \n",
      "\n",
      "    support  confidence       lift  \n",
      "64     0.04         1.0  16.666667  \n",
      "53     0.04         1.0  12.500000  \n",
      "60     0.04         1.0  12.500000  \n",
      "32     0.04         1.0  12.500000  \n",
      "48     0.04         1.0  10.000000  \n",
      "61     0.04         1.0  10.000000  \n"
     ]
    }
   ],
   "source": [
    "rules_synthetic = rules_synthetic.sort_values(\n",
    "    by='lift', ascending=False\n",
    ")\n",
    "\n",
    "top_6_uplift = rules_synthetic.head(6)[\n",
    "    ['antecedents', 'consequents',\n",
    "     'support', 'confidence', 'lift']\n",
    "]\n",
    "\n",
    "print(\"\\nTop 6 Synthetic Rules (by Lift):\")\n",
    "print(top_6_uplift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0e1d7",
   "metadata": {},
   "source": [
    "QUESTION 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "17187b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 Ratings:\n",
      "   userID  itemID  rating\n",
      "0     684      49       2\n",
      "1     559      63       3\n",
      "2     629       9       5\n",
      "3     192      24       1\n",
      "4     835      68       4\n",
      "5     763      26       5\n",
      "6     707      52       1\n",
      "7     359      54       1\n",
      "8       9      85       4\n",
      "9     723      78       5\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "n_ratings = 5000\n",
    "\n",
    "df_ratings = pd.DataFrame({\n",
    "    'userID': np.random.randint(0, 1000, n_ratings),\n",
    "    'itemID': np.random.randint(0, 100, n_ratings),\n",
    "    'rating': np.random.randint(1, 6, n_ratings)\n",
    "})\n",
    "\n",
    "print(\"\\nFirst 10 Ratings:\")\n",
    "print(df_ratings.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eda08d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainset users: 972\n",
      "Trainset items: 100\n",
      "Testset size: 1250\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(\n",
    "    df_ratings[['userID', 'itemID', 'rating']],\n",
    "    reader\n",
    ")\n",
    "\n",
    "trainset, testset = train_test_split(\n",
    "    data, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "print(\"\\nTrainset users:\", trainset.n_users)\n",
    "print(\"Trainset items:\", trainset.n_items)\n",
    "print(\"Testset size:\", len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6800446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x291379b5dc0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    "\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f688d07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Recommendations:\n",
      "User 809: Recommended Item 0 (Predicted Rating: 4.00)\n",
      "User 355: Recommended Item 71 (Predicted Rating: 4.53)\n",
      "User 503: Recommended Item 71 (Predicted Rating: 4.00)\n",
      "User 362: Recommended Item 71 (Predicted Rating: 5.00)\n",
      "User 637: Recommended Item 0 (Predicted Rating: 3.66)\n"
     ]
    }
   ],
   "source": [
    "anti_testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(anti_testset)\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=1):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    for uid in top_n:\n",
    "        top_n[uid].sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = top_n[uid][:n]\n",
    "    return top_n\n",
    "\n",
    "\n",
    "top_recommendations = get_top_n(predictions, n=1)\n",
    "\n",
    "print(\"\\nSample Recommendations:\")\n",
    "for uid in list(top_recommendations.keys())[:5]:\n",
    "    print(f\"User {uid}: Recommended Item \"\n",
    "          f\"{top_recommendations[uid][0][0]} \"\n",
    "          f\"(Predicted Rating: \"\n",
    "          f\"{top_recommendations[uid][0][1]:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
